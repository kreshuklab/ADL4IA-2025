{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cxJNtcLHyxK7"
   },
   "source": [
    "# Load and view data\n",
    "\n",
    "The most time-consuming and frustrating part of using Deep Learning for image analysis is data handling. The goal of this task is to get some of the data access and cleaning issues out of the way - then during the in-person course we will be able to run fun experiments and try different methods rather than spend time uploading and renaming files.\n",
    "\n",
    "The result of doing this task should be a small tutorial for how to use your data. Ideally, an external person should be able to run this notebook and get an idea how your data is organized, how to open and view it, and what the goal of your analysis is.\n",
    "\n",
    "We will use the [nuclei segmentation data](https://www.kaggle.com/c/data-science-bowl-2018/data) as an example. It's a dataset for a pretty standard segmentation task. If your task is not segmentation, some of the parts might not make sense. Instead of trying to stay as close as possible to the example, think what makes most sense for your own data. If you are not sure what to do, don't hesitate to contact your group's TAs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading the data - BARD\n",
    "\n",
    "Data used in webinars is already downloaded and can be found in `/scratch/k8s/denbi/ADL4IA_pre-course/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/scratch/k8s/denbi/ADL4IA_pre-course/kaggle_data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -ltrh {data_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d5CNxOpgx-ey"
   },
   "source": [
    "## The libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IK0BTeevRv_N"
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import imageio.v2 as imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from skimage.color import rgb2gray, rgba2rgb\n",
    "import napari"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rFTBWHvqLYwL"
   },
   "source": [
    "## Clean up data and upload to BARD\n",
    "\n",
    "Organize the data you want to use for the course and upload it to BARD. Refer to the upload instructions in the e-Campus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "89JYxq-bL-Q3"
   },
   "source": [
    "## Data description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task\n",
    "\n",
    "Write a short description of your data. Include the following information:\n",
    "\n",
    "- Context: where data comes from and what is the image analysis task\t\n",
    "- Folder structure, file naming scheme, image channels\n",
    "- File format(s)\n",
    "- What metadata is important for the task and how to find it? Metadata can include pixel size, ground truth labels, sample names or experiments and be found in file names, image file metadata or in a separate annotation table\n",
    "\n",
    "### Example\n",
    "Look at the [description on the page of the competition](https://www.kaggle.com/c/data-science-bowl-2018/data), especially the File description section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tuRXDRJsMxVo"
   },
   "source": [
    "## Load data as `numpy` array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`numpy` arrays are a basic way to represent multidimensional arrays. If you know how to open an image as a `numpy` array, most likely it will be possible to use the data for pretty much any kind of analysis in Python.\n",
    "\n",
    "- If your images are in `tiff` format, you can use `imageio`\n",
    "- If your images are in some format specific for the microscope, for example, `nd2`, `lif`, `vsi`, you might be able to open it using [`python-bioformats`](https://pythonhosted.org/python-bioformats/) to load them\n",
    "- If your images are large, consider converting them to [`zarr`](https://zarr.readthedocs.io/en/stable/) format to be able to quickly load part of the image without loading the whole image into memory "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task\n",
    "- Choose one or two samples and load all corresponding images into a `numpy` array\n",
    "- Plot the image\n",
    "- Check image size, data type and value distribution. Are they as you expect?\n",
    "- If the images are very large, try to convert your data to `zarr` and read only parts of the data at a time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_sample(data_dir, sample_name):\n",
    "    data_dir = Path(data_dir)\n",
    "    image_path = data_dir / sample_name / 'images' / f\"{sample_name}.png\"\n",
    "    \n",
    "    image = imageio.imread(image_path)\n",
    "    if image.shape[-1] == 4:\n",
    "        image = rgba2rgb(image)\n",
    "    if image.shape[-1] == 3:\n",
    "        image = rgb2gray(image)\n",
    "    masks_dir = data_dir / sample_name / 'masks'\n",
    "    # masks directory has multiple images - one mask per nucleus\n",
    "    masks_list = list(masks_dir.glob(\"*png\"))\n",
    "    # create an empty array\n",
    "    mask = np.zeros_like(image)\n",
    "    # iterate through the images to sum them up to one mask\n",
    "    for idx, mask_name in enumerate(masks_list):\n",
    "        one_nucleus_mask = imageio.imread(mask_name)\n",
    "        # add this nucleus to the mask\n",
    "        mask += one_nucleus_mask * (idx + 1)\n",
    "    return image, mask\n",
    "\n",
    "\n",
    "def plot_sample(image, mask):\n",
    "    plt.figure()\n",
    "    plt.imshow(image, cmap=\"Greys_r\")\n",
    "    plt.imshow(mask, cmap=\"prism\", alpha=0.2 * (mask>0).astype(np.float32))\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.hist(image.flatten(), bins=50)\n",
    "    plt.title(\"Intensity distribution of raw image\")\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"Image shape\", image.shape)\n",
    "    print(\"Image dtype\", image.dtype)\n",
    "    print(\"Mask dtype\", mask.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path(data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Raw image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_name = \"98a463483fe3a56deacc8bc00ab8aa62668bd40ad0c70bbe7deb10d3e4aeb0c0\"\n",
    "image, mask = load_sample(data_dir / \"nuclei_train_data\", sample_name)\n",
    "plot_sample(image, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_name = \"2a2032c4ed78f3fc64de7e5efd0bec26a81680b07404eaa54a1744b7ab3f8365\"\n",
    "image, mask = load_sample(data_dir / \"nuclei_train_data\", sample_name)\n",
    "plot_sample(image, mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task\n",
    "\n",
    "Training a deep learning model is based on random sampling of the dataset. Implement a function that outputs a random sample/ground truth  pair out of your dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_sample(dataset_dir):\n",
    "    dataset_dir = Path(dataset_dir)\n",
    "    sample_list = [sample_dir.name for sample_dir in dataset_dir.glob(\"*\")]\n",
    "    idx = np.random.randint(0, len(sample_list))\n",
    "    image, mask = load_sample(dataset_dir, sample_list[idx])\n",
    "    return image, mask, sample_list[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, mask, sample_name = get_random_sample(data_dir / \"nuclei_train_data\")\n",
    "print(sample_name)\n",
    "plot_sample(image, mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View data in `napari`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[`napari`](https://napari.org/stable/) is a data viewer designed for multi-dimensional biological images. We recommend to use it because it's easy to interact with `napari` from `python`. Look at the [general intro to napari](https://napari.org/stable/tutorials/fundamentals/viewer.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task\n",
    "\n",
    "Start `napari` from the notebook and create layers for some example images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = napari.Viewer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, mask, sample_name =  get_random_sample(data_dir / \"nuclei_train_data\")\n",
    "v.add_image(image, name=\"raw\")\n",
    "v.add_labels(mask.astype(np.uint16), name=\"mask\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running previous two cells you should see a separate window looking something like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from napari.utils import nbscreenshot\n",
    "\n",
    "nbscreenshot(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hints\n",
    "- What [layer type](https://napari.org/stable/howtos/layers/index.html) fits your data best?\n",
    "- If your data has multiple channels, add each channel as a separate layer and experiment with blending modes/visibility\n",
    "- What visualization will be the best for checking the prediction quality in the future? Does it make sense to transform the data before visualizing, for example, take a difference of ground truth and prediction? "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Untitled",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "dl-image-pytorch-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
